{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb44a1e8-eadd-4888-b838-3e070ea0eb9f",
   "metadata": {},
   "source": [
    "# Feature selection using Bees Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a707c3a-da6b-4515-ab5f-d9b10939004c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from niapy.problems import Problem\n",
    "from niapy.task import Task\n",
    "\n",
    "from niapy.algorithms.basic import BeesAlgorithm\n",
    "import pandas as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fafa246d-2595-42cc-b464-e50e236d6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNBFeatureSelection(Problem):\n",
    "    def __init__(self, X_train, y_train, alpha=0.99):\n",
    "        super().__init__(dimension=X_train.shape[1], lower=0, upper=1)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _evaluate(self, x):\n",
    "        selected = x > 0.5\n",
    "        num_selected = selected.sum()\n",
    "        if num_selected == 0:\n",
    "            return 1.0\n",
    "        accuracy = cross_val_score(GaussianNB(), self.X_train[:, selected], self.y_train, cv=2, n_jobs=-1).mean()\n",
    "        score = 1 - accuracy\n",
    "        num_features = self.X_train.shape[1]\n",
    "        return self.alpha * score + (1 - self.alpha) * (num_selected / num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8fa41c5-0c38-48d0-9659-81524ac3bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionFeatureSelection(Problem):\n",
    "    def __init__(self, X_train, y_train, alpha=0.99):\n",
    "        super().__init__(dimension=X_train.shape[1], lower=0, upper=1)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _evaluate(self, x):\n",
    "        selected = x > 0.5\n",
    "        num_selected = selected.sum()\n",
    "        if num_selected == 0:\n",
    "            return 1.0\n",
    "        accuracy = cross_val_score(LogisticRegression(), self.X_train[:, selected], self.y_train, cv=2, n_jobs=-1).mean()\n",
    "        score = 1 - accuracy\n",
    "        num_features = self.X_train.shape[1]\n",
    "        return self.alpha * score + (1 - self.alpha) * (num_selected / num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b891ab1f-b02d-41f0-9d14-fdeed4be5450",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifierFeatureSelection(Problem):\n",
    "    def __init__(self, X_train, y_train, alpha=0.99):\n",
    "        super().__init__(dimension=X_train.shape[1], lower=0, upper=1)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _evaluate(self, x):\n",
    "        selected = x > 0.5\n",
    "        num_selected = selected.sum()\n",
    "        if num_selected == 0:\n",
    "            return 1.0\n",
    "        accuracy = cross_val_score(DecisionTreeClassifier(), self.X_train[:, selected], self.y_train, cv=2, n_jobs=-1).mean()\n",
    "        score = 1 - accuracy\n",
    "        num_features = self.X_train.shape[1]\n",
    "        return self.alpha * score + (1 - self.alpha) * (num_selected / num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62a909cb-40f3-4188-8a18-40f657be1743",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNeighborsClassifierFeatureSelection(Problem):\n",
    "    def __init__(self, X_train, y_train, alpha=0.99):\n",
    "        super().__init__(dimension=X_train.shape[1], lower=0, upper=1)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _evaluate(self, x):\n",
    "        selected = x > 0.5\n",
    "        num_selected = selected.sum()\n",
    "        if num_selected == 0:\n",
    "            return 1.0\n",
    "        accuracy = cross_val_score(KNeighborsClassifier(), self.X_train[:, selected], self.y_train, cv=2, n_jobs=-1).mean()\n",
    "        score = 1 - accuracy\n",
    "        num_features = self.X_train.shape[1]\n",
    "        return self.alpha * score + (1 - self.alpha) * (num_selected / num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "367636ee-a4e4-4dda-925c-1a232e41eab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SVMFeatureSelection(Problem):\n",
    "    def __init__(self, X_train, y_train, alpha=0.99):\n",
    "        super().__init__(dimension=X_train.shape[1], lower=0, upper=1)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _evaluate(self, x):\n",
    "        selected = x > 0.5\n",
    "        num_selected = selected.sum()\n",
    "        if num_selected == 0:\n",
    "            return 1.0\n",
    "        accuracy = cross_val_score(SVC(), self.X_train[:, selected], self.y_train, cv=2, n_jobs=-1).mean()\n",
    "        score = 1 - accuracy\n",
    "        num_features = self.X_train.shape[1]\n",
    "        return self.alpha * score + (1 - self.alpha) * (num_selected / num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b02e4ad-1af4-449b-9b31-9b259688aedd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "feature_names = dataset.feature_names\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1234)\n",
    "\n",
    "problem_nb = GaussianNBFeatureSelection(X_train, y_train)\n",
    "problem_lr = LogisticRegressionFeatureSelection(X_train, y_train)\n",
    "problem_dt = DecisionTreeClassifierFeatureSelection(X_train, y_train)\n",
    "problem_knn = KNeighborsClassifierFeatureSelection(X_train, y_train)\n",
    "problem_svc = SVMFeatureSelection(X_train, y_train)\n",
    "#task = Task(problem, max_iters=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c51f30-1e67-4d0d-8392-a916cf03e6e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beedict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b49e5a-b33f-4ec5-b681-d9feeeae3a4e",
   "metadata": {},
   "source": [
    "# Bees Algorithm (1/3: Change to population size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cf437b8-30ec-45e0-8d80-205f0865b583",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Bees algorithm: Population size = 10\n",
      "Number of selected features: 8\n",
      "Selected features: concave points error, worst radius, worst texture, worst perimeter, worst area, worst smoothness, worst compactness, worst symmetry\n",
      "GaussianNB - Subset accuracy: 0.9736842105263158\n",
      "GaussianNB - All Features Accuracy: 0.9649122807017544\n",
      "--------------------------------------------------\n",
      "Bees algorithm: Population size = 10\n",
      "Number of selected features: 15\n",
      "Selected features: mean radius, mean texture, mean smoothness, mean concavity, mean concave points, texture error, perimeter error, area error, compactness error, concavity error, concave points error, worst area, worst compactness, worst concave points, worst fractal dimension\n",
      "DecisionTreeClassifier - Subset accuracy: 1.0\n",
      "DecisionTreeClassifier - All Features Accuracy: 0.9736842105263158\n",
      "--------------------------------------------------\n",
      "Bees algorithm: Population size = 10\n",
      "Number of selected features: 11\n",
      "Selected features: mean texture, mean concavity, mean symmetry, smoothness error, compactness error, symmetry error, worst radius, worst perimeter, worst concavity, worst symmetry, worst fractal dimension\n",
      "KNeighborsClassifier - Subset accuracy: 0.9649122807017544\n",
      "KNeighborsClassifier - All Features Accuracy: 0.9210526315789473\n",
      "--------------------------------------------------\n",
      "Bees algorithm: Population size = 10\n",
      "Number of selected features: 10\n",
      "Selected features: mean radius, mean texture, mean fractal dimension, radius error, texture error, worst radius, worst texture, worst perimeter, worst concave points, worst symmetry\n",
      "SVC - Subset accuracy: 0.956140350877193\n",
      "SVC - All Features Accuracy: 0.9122807017543859\n",
      "--------------------------------------------------\n",
      "Bees algorithm: Population size = 40\n",
      "Number of selected features: 9\n",
      "Selected features: mean symmetry, compactness error, concave points error, worst radius, worst texture, worst perimeter, worst area, worst concave points, worst symmetry\n",
      "GaussianNB - Subset accuracy: 0.9649122807017544\n",
      "GaussianNB - All Features Accuracy: 0.9649122807017544\n",
      "--------------------------------------------------\n",
      "Bees algorithm: Population size = 40\n",
      "Number of selected features: 15\n",
      "Selected features: mean radius, mean texture, mean perimeter, mean smoothness, mean compactness, mean fractal dimension, perimeter error, concavity error, concave points error, symmetry error, fractal dimension error, worst texture, worst area, worst smoothness, worst compactness\n",
      "DecisionTreeClassifier - Subset accuracy: 0.9385964912280702\n",
      "DecisionTreeClassifier - All Features Accuracy: 0.9649122807017544\n",
      "--------------------------------------------------\n",
      "Bees algorithm: Population size = 40\n",
      "Number of selected features: 7\n",
      "Selected features: mean texture, mean symmetry, radius error, worst radius, worst perimeter, worst smoothness, worst compactness\n",
      "KNeighborsClassifier - Subset accuracy: 0.956140350877193\n",
      "KNeighborsClassifier - All Features Accuracy: 0.9210526315789473\n",
      "--------------------------------------------------\n",
      "Bees algorithm: Population size = 40\n",
      "Number of selected features: 6\n",
      "Selected features: mean texture, mean concavity, symmetry error, fractal dimension error, worst texture, worst perimeter\n",
      "SVC - Subset accuracy: 0.956140350877193\n",
      "SVC - All Features Accuracy: 0.9122807017543859\n",
      "--------------------------------------------------\n",
      "Bees algorithm: Population size = 70\n",
      "Number of selected features: 9\n",
      "Selected features: mean texture, mean smoothness, compactness error, concave points error, symmetry error, worst area, worst smoothness, worst concave points, worst fractal dimension\n",
      "GaussianNB - Subset accuracy: 0.9649122807017544\n",
      "GaussianNB - All Features Accuracy: 0.9649122807017544\n",
      "--------------------------------------------------\n",
      "Bees algorithm: Population size = 70\n",
      "Number of selected features: 14\n",
      "Selected features: mean radius, mean texture, mean area, mean compactness, mean concave points, mean fractal dimension, texture error, perimeter error, area error, concave points error, worst area, worst smoothness, worst concave points, worst fractal dimension\n",
      "DecisionTreeClassifier - Subset accuracy: 0.9824561403508771\n",
      "DecisionTreeClassifier - All Features Accuracy: 0.956140350877193\n",
      "--------------------------------------------------\n",
      "Bees algorithm: Population size = 70\n",
      "Number of selected features: 7\n",
      "Selected features: mean texture, mean smoothness, smoothness error, compactness error, worst radius, worst perimeter, worst symmetry\n",
      "KNeighborsClassifier - Subset accuracy: 0.9649122807017544\n",
      "KNeighborsClassifier - All Features Accuracy: 0.9210526315789473\n",
      "--------------------------------------------------\n",
      "Bees algorithm: Population size = 70\n",
      "Number of selected features: 7\n",
      "Selected features: mean compactness, mean concavity, mean concave points, mean fractal dimension, concavity error, fractal dimension error, worst concave points\n",
      "SVC - Subset accuracy: 0.9385964912280702\n",
      "SVC - All Features Accuracy: 0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "# Set saved variable for checked parameters\n",
    "bestScore = 0.0\n",
    "bestCriterion = None\n",
    "pop_num = 0\n",
    "pop_features = None\n",
    "\n",
    "for x in range(10,100,30):\n",
    "    # GaussianNB\n",
    "    task = Task(problem_nb, max_iters=200)\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    print(\"Bees algorithm: Population size = \"+ str(x))\n",
    "    algorithm = BeesAlgorithm(population_size=x, m=5, e=4, ngh=1, nep=4, nsp=2)\n",
    "    best_features, best_fitness = algorithm.run(task=task)\n",
    "    selected_features = best_features > 0.5\n",
    "    print('Number of selected features:', selected_features.sum())\n",
    "    print('Selected features:', ', '.join(feature_names[selected_features].tolist()))\n",
    "    features1 = feature_names[selected_features].tolist()\n",
    "    \n",
    "    model_selected = GaussianNB()\n",
    "    model_all = GaussianNB()\n",
    "    model_name = \"GaussianNB\"\n",
    "\n",
    "    model_selected.fit(X_train[:, selected_features], y_train)\n",
    "    subset_acc = model_selected.score(X_test[:, selected_features], y_test)\n",
    "    print(model_name + ' - Subset accuracy:', subset_acc)\n",
    "    if subset_acc > bestScore:\n",
    "        bestScore = subset_acc\n",
    "        bestCriterion = x\n",
    "        pop_num = selected_features.sum()\n",
    "        pop_features = feature_names[selected_features].tolist()\n",
    "    model_all.fit(X_train, y_train)\n",
    "    print(model_name + ' - All Features Accuracy:', model_all.score(X_test, y_test))\n",
    "    \n",
    "    # DecisionTreeClassifier\n",
    "    task = Task(problem_dt, max_iters=200)\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    print(\"Bees algorithm: Population size = \"+ str(x))\n",
    "    algorithm = BeesAlgorithm(population_size=x, m=5, e=4, ngh=1, nep=4, nsp=2)\n",
    "    best_features, best_fitness = algorithm.run(task=task)\n",
    "    selected_features = best_features > 0.5\n",
    "    print('Number of selected features:', selected_features.sum())\n",
    "    print('Selected features:', ', '.join(feature_names[selected_features].tolist()))\n",
    "    features1 = feature_names[selected_features].tolist()\n",
    "    \n",
    "    model_selected = DecisionTreeClassifier()\n",
    "    model_all = DecisionTreeClassifier()\n",
    "    model_name = \"DecisionTreeClassifier\"\n",
    "\n",
    "    model_selected.fit(X_train[:, selected_features], y_train)\n",
    "    subset_acc = model_selected.score(X_test[:, selected_features], y_test)\n",
    "    print(model_name + ' - Subset accuracy:', subset_acc)\n",
    "    if subset_acc > bestScore:\n",
    "        bestScore = subset_acc\n",
    "        bestCriterion = x\n",
    "        pop_num = selected_features.sum()\n",
    "        pop_features = feature_names[selected_features].tolist()\n",
    "    model_all.fit(X_train, y_train)\n",
    "    print(model_name + ' - All Features Accuracy:', model_all.score(X_test, y_test))\n",
    "    \n",
    "    # KNeighborsClassifier\n",
    "    task = Task(problem_knn, max_iters=200)\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    print(\"Bees algorithm: Population size = \"+ str(x))\n",
    "    algorithm = BeesAlgorithm(population_size=x, m=5, e=4, ngh=1, nep=4, nsp=2)\n",
    "    best_features, best_fitness = algorithm.run(task=task)\n",
    "    selected_features = best_features > 0.5\n",
    "    print('Number of selected features:', selected_features.sum())\n",
    "    print('Selected features:', ', '.join(feature_names[selected_features].tolist()))\n",
    "    features1 = feature_names[selected_features].tolist()\n",
    "    \n",
    "    model_selected = KNeighborsClassifier()\n",
    "    model_all = KNeighborsClassifier()\n",
    "    model_name = \"KNeighborsClassifier\"\n",
    "\n",
    "    model_selected.fit(X_train[:, selected_features], y_train)\n",
    "    subset_acc = model_selected.score(X_test[:, selected_features], y_test)\n",
    "    print(model_name + ' - Subset accuracy:', subset_acc)\n",
    "    if subset_acc > bestScore:\n",
    "        bestScore = subset_acc\n",
    "        bestCriterion = x\n",
    "        pop_num = selected_features.sum()\n",
    "        pop_features = feature_names[selected_features].tolist()\n",
    "    model_all.fit(X_train, y_train)\n",
    "    print(model_name + ' - All Features Accuracy:', model_all.score(X_test, y_test))\n",
    "    \n",
    "    # SVC\n",
    "    task = Task(problem_svc, max_iters=200)\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    print(\"Bees algorithm: Population size = \"+ str(x))\n",
    "    algorithm = BeesAlgorithm(population_size=x, m=5, e=4, ngh=1, nep=4, nsp=2)\n",
    "    best_features, best_fitness = algorithm.run(task=task)\n",
    "    selected_features = best_features > 0.5\n",
    "    print('Number of selected features:', selected_features.sum())\n",
    "    print('Selected features:', ', '.join(feature_names[selected_features].tolist()))\n",
    "    features1 = feature_names[selected_features].tolist()\n",
    "    \n",
    "    model_selected = SVC()\n",
    "    model_all = SVC()\n",
    "    model_name = \"SVC\"\n",
    "\n",
    "    model_selected.fit(X_train[:, selected_features], y_train)\n",
    "    subset_acc = model_selected.score(X_test[:, selected_features], y_test)\n",
    "    print(model_name + ' - Subset accuracy:', subset_acc)\n",
    "    if subset_acc > bestScore:\n",
    "        bestScore = subset_acc\n",
    "        bestCriterion = x\n",
    "        pop_num = selected_features.sum()\n",
    "        pop_features = feature_names[selected_features].tolist()\n",
    "    model_all.fit(X_train, y_train)\n",
    "    print(model_name + ' - All Features Accuracy:', model_all.score(X_test, y_test))\n",
    "\n",
    "beedict[\"Bees-Population\"] = \"pop: \" + str(bestCriterion) + \", accuracy: \" + str(round(bestScore, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23908b2e-77b0-4101-913a-e688bb590b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bees-Population': 'pop: 10, accuracy: 1.0'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beedict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390b581b-44d3-4990-b2a7-262624b2bbe3",
   "metadata": {},
   "source": [
    "# Bees Algorithm (2/3: Change to the number of selected sites (m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fba49f79-60e4-48b4-8efb-0d777e853a83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Bees algorithm: m = 1\n",
      "Number of selected features: 7\n",
      "Selected features: mean texture, mean smoothness, mean symmetry, fractal dimension error, worst radius, worst texture, worst concavity\n",
      "GaussianNB - Subset accuracy: 0.9649122807017544\n",
      "GaussianNB - All Features Accuracy: 0.9649122807017544\n",
      "--------------------------------------------------\n",
      "Bees algorithm: m = 1\n",
      "Number of selected features: 10\n",
      "Selected features: mean texture, mean perimeter, mean concave points, perimeter error, compactness error, worst texture, worst area, worst compactness, worst concave points, worst fractal dimension\n",
      "DecisionTreeClassifier - Subset accuracy: 0.9385964912280702\n",
      "DecisionTreeClassifier - All Features Accuracy: 0.956140350877193\n",
      "--------------------------------------------------\n",
      "Bees algorithm: m = 1\n",
      "Number of selected features: 7\n",
      "Selected features: mean texture, mean smoothness, radius error, worst radius, worst perimeter, worst compactness, worst fractal dimension\n",
      "KNeighborsClassifier - Subset accuracy: 0.956140350877193\n",
      "KNeighborsClassifier - All Features Accuracy: 0.9210526315789473\n",
      "--------------------------------------------------\n",
      "Bees algorithm: m = 1\n",
      "Number of selected features: 9\n",
      "Selected features: mean texture, mean smoothness, mean compactness, radius error, perimeter error, worst radius, worst texture, worst perimeter, worst fractal dimension\n",
      "SVC - Subset accuracy: 0.956140350877193\n",
      "SVC - All Features Accuracy: 0.9122807017543859\n",
      "--------------------------------------------------\n",
      "Bees algorithm: m = 4\n",
      "Number of selected features: 10\n",
      "Selected features: mean texture, mean perimeter, radius error, texture error, concavity error, fractal dimension error, worst radius, worst texture, worst smoothness, worst concave points\n",
      "GaussianNB - Subset accuracy: 0.9649122807017544\n",
      "GaussianNB - All Features Accuracy: 0.9649122807017544\n",
      "--------------------------------------------------\n",
      "Bees algorithm: m = 4\n",
      "Number of selected features: 13\n",
      "Selected features: mean texture, mean concavity, mean concave points, mean fractal dimension, area error, compactness error, concavity error, symmetry error, worst texture, worst area, worst smoothness, worst concavity, worst concave points\n",
      "DecisionTreeClassifier - Subset accuracy: 0.9912280701754386\n",
      "DecisionTreeClassifier - All Features Accuracy: 0.9649122807017544\n",
      "--------------------------------------------------\n",
      "Bees algorithm: m = 4\n",
      "Number of selected features: 8\n",
      "Selected features: mean texture, mean compactness, mean fractal dimension, radius error, compactness error, worst radius, worst perimeter, worst smoothness\n",
      "KNeighborsClassifier - Subset accuracy: 0.956140350877193\n",
      "KNeighborsClassifier - All Features Accuracy: 0.9210526315789473\n",
      "--------------------------------------------------\n",
      "Bees algorithm: m = 4\n",
      "Number of selected features: 9\n",
      "Selected features: mean radius, mean texture, mean compactness, smoothness error, compactness error, fractal dimension error, worst texture, worst perimeter, worst compactness\n",
      "SVC - Subset accuracy: 0.956140350877193\n",
      "SVC - All Features Accuracy: 0.9122807017543859\n",
      "--------------------------------------------------\n",
      "Bees algorithm: m = 7\n",
      "Number of selected features: 12\n",
      "Selected features: mean texture, mean concave points, mean symmetry, mean fractal dimension, texture error, compactness error, fractal dimension error, worst texture, worst area, worst smoothness, worst concave points, worst symmetry\n",
      "GaussianNB - Subset accuracy: 0.9649122807017544\n",
      "GaussianNB - All Features Accuracy: 0.9649122807017544\n",
      "--------------------------------------------------\n",
      "Bees algorithm: m = 7\n",
      "Number of selected features: 12\n",
      "Selected features: mean compactness, mean concavity, mean concave points, texture error, perimeter error, compactness error, concavity error, concave points error, worst radius, worst texture, worst perimeter, worst area\n",
      "DecisionTreeClassifier - Subset accuracy: 0.9649122807017544\n",
      "DecisionTreeClassifier - All Features Accuracy: 0.9649122807017544\n",
      "--------------------------------------------------\n",
      "Bees algorithm: m = 7\n",
      "Number of selected features: 8\n",
      "Selected features: mean radius, mean texture, mean concave points, radius error, perimeter error, worst perimeter, worst smoothness, worst concavity\n",
      "KNeighborsClassifier - Subset accuracy: 0.956140350877193\n",
      "KNeighborsClassifier - All Features Accuracy: 0.9210526315789473\n",
      "--------------------------------------------------\n",
      "Bees algorithm: m = 7\n",
      "Number of selected features: 6\n",
      "Selected features: mean texture, mean concave points, mean symmetry, radius error, worst texture, worst perimeter\n",
      "SVC - Subset accuracy: 0.956140350877193\n",
      "SVC - All Features Accuracy: 0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "# Set saved variable for checked parameters\n",
    "bestScore = 0.0\n",
    "bestCriterion = None\n",
    "m_num = 0\n",
    "m_features = None\n",
    "\n",
    "for x in range(1,10,3):\n",
    "    # GaussianNB\n",
    "    task = Task(problem_nb, max_iters=200)\n",
    "        \n",
    "    print(\"-\"*50)\n",
    "    print(\"Bees algorithm: m = \"+ str(x))\n",
    "    algorithm = BeesAlgorithm(population_size=40, m=x, e=4, ngh=1, nep=4, nsp=2)\n",
    "    best_features, best_fitness = algorithm.run(task=task)\n",
    "    selected_features = best_features > 0.5\n",
    "    print('Number of selected features:', selected_features.sum())\n",
    "    print('Selected features:', ', '.join(feature_names[selected_features].tolist()))\n",
    "    features1 = feature_names[selected_features].tolist()\n",
    "        \n",
    "    model_selected = GaussianNB()\n",
    "    model_all = GaussianNB()\n",
    "    model_name = \"GaussianNB\"\n",
    "\n",
    "    model_selected.fit(X_train[:, selected_features], y_train)\n",
    "    subset_acc = model_selected.score(X_test[:, selected_features], y_test)\n",
    "    print(model_name + ' - Subset accuracy:', subset_acc)\n",
    "    if subset_acc > bestScore:\n",
    "        bestScore = subset_acc\n",
    "        bestCriterion = x\n",
    "        m_num = selected_features.sum()\n",
    "        m_features = feature_names[selected_features].tolist()\n",
    "        \n",
    "    model_all.fit(X_train, y_train)\n",
    "    print(model_name + ' - All Features Accuracy:', model_all.score(X_test, y_test))\n",
    "    \n",
    "    # DecisionTreeClassifier\n",
    "    task = Task(problem_dt, max_iters=200)\n",
    "        \n",
    "    print(\"-\"*50)\n",
    "    print(\"Bees algorithm: m = \"+ str(x))\n",
    "    algorithm = BeesAlgorithm(population_size=40, m=x, e=4, ngh=1, nep=4, nsp=2)\n",
    "    best_features, best_fitness = algorithm.run(task=task)\n",
    "    selected_features = best_features > 0.5\n",
    "    print('Number of selected features:', selected_features.sum())\n",
    "    print('Selected features:', ', '.join(feature_names[selected_features].tolist()))\n",
    "    features1 = feature_names[selected_features].tolist()\n",
    "        \n",
    "    model_selected = DecisionTreeClassifier()\n",
    "    model_all = DecisionTreeClassifier()\n",
    "    model_name = \"DecisionTreeClassifier\"\n",
    "\n",
    "    model_selected.fit(X_train[:, selected_features], y_train)\n",
    "    subset_acc = model_selected.score(X_test[:, selected_features], y_test)\n",
    "    print(model_name + ' - Subset accuracy:', subset_acc)\n",
    "    if subset_acc > bestScore:\n",
    "        bestScore = subset_acc\n",
    "        bestCriterion = x\n",
    "        m_num = selected_features.sum()\n",
    "        m_features = feature_names[selected_features].tolist()\n",
    "        \n",
    "    model_all.fit(X_train, y_train)\n",
    "    print(model_name + ' - All Features Accuracy:', model_all.score(X_test, y_test))\n",
    "    \n",
    "    # KNeighborsClassifier\n",
    "    task = Task(problem_knn, max_iters=200)\n",
    "        \n",
    "    print(\"-\"*50)\n",
    "    print(\"Bees algorithm: m = \"+ str(x))\n",
    "    algorithm = BeesAlgorithm(population_size=40, m=x, e=4, ngh=1, nep=4, nsp=2)\n",
    "    best_features, best_fitness = algorithm.run(task=task)\n",
    "    selected_features = best_features > 0.5\n",
    "    print('Number of selected features:', selected_features.sum())\n",
    "    print('Selected features:', ', '.join(feature_names[selected_features].tolist()))\n",
    "    features1 = feature_names[selected_features].tolist()\n",
    "        \n",
    "    model_selected = KNeighborsClassifier()\n",
    "    model_all = KNeighborsClassifier()\n",
    "    model_name = \"KNeighborsClassifier\"\n",
    "\n",
    "    model_selected.fit(X_train[:, selected_features], y_train)\n",
    "    subset_acc = model_selected.score(X_test[:, selected_features], y_test)\n",
    "    print(model_name + ' - Subset accuracy:', subset_acc)\n",
    "    if subset_acc > bestScore:\n",
    "        bestScore = subset_acc\n",
    "        bestCriterion = x\n",
    "        m_num = selected_features.sum()\n",
    "        m_features = feature_names[selected_features].tolist()\n",
    "        \n",
    "    model_all.fit(X_train, y_train)\n",
    "    print(model_name + ' - All Features Accuracy:', model_all.score(X_test, y_test))\n",
    "    \n",
    "    # SVC\n",
    "    task = Task(problem_svc, max_iters=200)\n",
    "        \n",
    "    print(\"-\"*50)\n",
    "    print(\"Bees algorithm: m = \"+ str(x))\n",
    "    algorithm = BeesAlgorithm(population_size=40, m=x, e=4, ngh=1, nep=4, nsp=2)\n",
    "    best_features, best_fitness = algorithm.run(task=task)\n",
    "    selected_features = best_features > 0.5\n",
    "    print('Number of selected features:', selected_features.sum())\n",
    "    print('Selected features:', ', '.join(feature_names[selected_features].tolist()))\n",
    "    features1 = feature_names[selected_features].tolist()\n",
    "        \n",
    "    model_selected = SVC()\n",
    "    model_all = SVC()\n",
    "    model_name = \"SVC\"\n",
    "\n",
    "    model_selected.fit(X_train[:, selected_features], y_train)\n",
    "    subset_acc = model_selected.score(X_test[:, selected_features], y_test)\n",
    "    print(model_name + ' - Subset accuracy:', subset_acc)\n",
    "    if subset_acc > bestScore:\n",
    "        bestScore = subset_acc\n",
    "        bestCriterion = x\n",
    "        m_num = selected_features.sum()\n",
    "        m_features = feature_names[selected_features].tolist()\n",
    "        \n",
    "    model_all.fit(X_train, y_train)\n",
    "    print(model_name + ' - All Features Accuracy:', model_all.score(X_test, y_test))\n",
    "    \n",
    "beedict[\"Bees-M\"] = \"m: \" + str(bestCriterion) + \", accuracy: \" + str(round(bestScore, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bd5bc2-70d0-4334-905e-b7e27eec5384",
   "metadata": {},
   "source": [
    "# Bees Algorithm (3/3: Change to number of recruits (nep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a5dcdce-2811-41ea-9ff1-3469be5ef6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Bees algorithm: nep = 1\n",
      "Number of selected features: 11\n",
      "Selected features: mean texture, mean area, mean concave points, mean symmetry, texture error, worst texture, worst area, worst smoothness, worst concavity, worst concave points, worst symmetry\n",
      "Subset accuracy: 0.9649122807017544\n",
      "All Features Accuracy: 0.9649122807017544\n",
      "--------------------------------------------------\n",
      "Bees algorithm: nep = 1\n",
      "Number of selected features: 10\n",
      "Selected features: mean texture, mean compactness, mean concave points, mean symmetry, radius error, texture error, area error, compactness error, worst area, worst concave points\n",
      "Subset accuracy: 0.9649122807017544\n",
      "All Features Accuracy: 0.9649122807017544\n",
      "--------------------------------------------------\n",
      "Bees algorithm: nep = 1\n",
      "Number of selected features: 10\n",
      "Selected features: mean radius, mean texture, mean fractal dimension, perimeter error, concavity error, symmetry error, fractal dimension error, worst radius, worst perimeter, worst compactness\n",
      "Subset accuracy: 0.956140350877193\n",
      "All Features Accuracy: 0.9210526315789473\n",
      "--------------------------------------------------\n",
      "Bees algorithm: nep = 1\n",
      "Number of selected features: 9\n",
      "Selected features: mean radius, mean texture, mean concavity, mean concave points, concave points error, worst radius, worst texture, worst perimeter, worst concave points\n",
      "Subset accuracy: 0.956140350877193\n",
      "All Features Accuracy: 0.9122807017543859\n",
      "--------------------------------------------------\n",
      "Bees algorithm: nep = 4\n",
      "Number of selected features: 10\n",
      "Selected features: mean texture, mean concave points, smoothness error, concavity error, symmetry error, fractal dimension error, worst radius, worst texture, worst concave points, worst symmetry\n",
      "Subset accuracy: 0.9473684210526315\n",
      "All Features Accuracy: 0.9649122807017544\n",
      "--------------------------------------------------\n",
      "Bees algorithm: nep = 4\n",
      "Number of selected features: 12\n",
      "Selected features: mean radius, mean texture, mean compactness, mean concavity, mean concave points, mean fractal dimension, area error, compactness error, worst radius, worst texture, worst perimeter, worst concave points\n",
      "Subset accuracy: 0.9473684210526315\n",
      "All Features Accuracy: 0.956140350877193\n",
      "--------------------------------------------------\n",
      "Bees algorithm: nep = 4\n",
      "Number of selected features: 8\n",
      "Selected features: mean radius, mean texture, mean smoothness, radius error, perimeter error, worst perimeter, worst smoothness, worst concavity\n",
      "Subset accuracy: 0.956140350877193\n",
      "All Features Accuracy: 0.9210526315789473\n",
      "--------------------------------------------------\n",
      "Bees algorithm: nep = 4\n",
      "Number of selected features: 9\n",
      "Selected features: mean texture, radius error, texture error, smoothness error, concave points error, symmetry error, worst radius, worst texture, worst perimeter\n",
      "Subset accuracy: 0.956140350877193\n",
      "All Features Accuracy: 0.9122807017543859\n",
      "--------------------------------------------------\n",
      "Bees algorithm: nep = 7\n",
      "Number of selected features: 10\n",
      "Selected features: mean texture, mean compactness, mean concave points, symmetry error, fractal dimension error, worst texture, worst perimeter, worst area, worst concave points, worst symmetry\n",
      "Subset accuracy: 0.9473684210526315\n",
      "All Features Accuracy: 0.9649122807017544\n",
      "--------------------------------------------------\n",
      "Bees algorithm: nep = 7\n",
      "Number of selected features: 13\n",
      "Selected features: mean perimeter, mean concave points, radius error, smoothness error, compactness error, concave points error, fractal dimension error, worst texture, worst area, worst compactness, worst concavity, worst concave points, worst symmetry\n",
      "Subset accuracy: 0.956140350877193\n",
      "All Features Accuracy: 0.956140350877193\n",
      "--------------------------------------------------\n",
      "Bees algorithm: nep = 7\n",
      "Number of selected features: 6\n",
      "Selected features: mean texture, mean concave points, symmetry error, worst radius, worst perimeter, worst symmetry\n",
      "Subset accuracy: 0.9649122807017544\n",
      "All Features Accuracy: 0.9210526315789473\n",
      "--------------------------------------------------\n",
      "Bees algorithm: nep = 7\n",
      "Number of selected features: 5\n",
      "Selected features: mean texture, mean concavity, worst radius, worst texture, worst perimeter\n",
      "Subset accuracy: 0.9473684210526315\n",
      "All Features Accuracy: 0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "# Set saved variable for checked parameters\n",
    "bestScore = 0.0\n",
    "bestCriterion = None\n",
    "nep_num = 0\n",
    "nep_features = None\n",
    "\n",
    "for x in range(1,10,3):\n",
    "    # GaussianNB\n",
    "    task = Task(problem_nb, max_iters=200)\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    print(\"Bees algorithm: nep = \"+ str(x))\n",
    "    algorithm = BeesAlgorithm(population_size=40, m=5, e=4, ngh=1, nep=x, nsp=2)\n",
    "    best_features, best_fitness = algorithm.run(task=task)\n",
    "    selected_features = best_features > 0.5\n",
    "    print('Number of selected features:', selected_features.sum())\n",
    "    print('Selected features:', ', '.join(feature_names[selected_features].tolist()))\n",
    "    features1 = feature_names[selected_features].tolist()\n",
    "        \n",
    "    model_selected = GaussianNB()\n",
    "    model_all = GaussianNB()\n",
    "    model_name = \"GaussianNB\"\n",
    "\n",
    "    model_selected.fit(X_train[:, selected_features], y_train)  \n",
    "    subset_acc = model_selected.score(X_test[:, selected_features], y_test)\n",
    "    print('Subset accuracy:', subset_acc)\n",
    "    if subset_acc > bestScore:\n",
    "        bestScore = subset_acc\n",
    "        bestCriterion = x\n",
    "        nep_num = selected_features.sum()\n",
    "        nep_features = feature_names[selected_features].tolist()\n",
    "    model_all.fit(X_train, y_train)\n",
    "    print('All Features Accuracy:', model_all.score(X_test, y_test))\n",
    "    \n",
    "    # DecisionTreeClassifier\n",
    "    task = Task(problem_dt, max_iters=200)\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    print(\"Bees algorithm: nep = \"+ str(x))\n",
    "    algorithm = BeesAlgorithm(population_size=40, m=5, e=4, ngh=1, nep=x, nsp=2)\n",
    "    best_features, best_fitness = algorithm.run(task=task)\n",
    "    selected_features = best_features > 0.5\n",
    "    print('Number of selected features:', selected_features.sum())\n",
    "    print('Selected features:', ', '.join(feature_names[selected_features].tolist()))\n",
    "    features1 = feature_names[selected_features].tolist()\n",
    "        \n",
    "    model_selected = DecisionTreeClassifier()\n",
    "    model_all = DecisionTreeClassifier()\n",
    "    model_name = \"DecisionTreeClassifier\"\n",
    "\n",
    "    model_selected.fit(X_train[:, selected_features], y_train)  \n",
    "    subset_acc = model_selected.score(X_test[:, selected_features], y_test)\n",
    "    print('Subset accuracy:', subset_acc)\n",
    "    if subset_acc > bestScore:\n",
    "        bestScore = subset_acc\n",
    "        bestCriterion = x\n",
    "        nep_num = selected_features.sum()\n",
    "        nep_features = feature_names[selected_features].tolist()\n",
    "    model_all.fit(X_train, y_train)\n",
    "    print('All Features Accuracy:', model_all.score(X_test, y_test))\n",
    "    \n",
    "    # KNeighborsClassifier\n",
    "    task = Task(problem_knn, max_iters=200)\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    print(\"Bees algorithm: nep = \"+ str(x))\n",
    "    algorithm = BeesAlgorithm(population_size=40, m=5, e=4, ngh=1, nep=x, nsp=2)\n",
    "    best_features, best_fitness = algorithm.run(task=task)\n",
    "    selected_features = best_features > 0.5\n",
    "    print('Number of selected features:', selected_features.sum())\n",
    "    print('Selected features:', ', '.join(feature_names[selected_features].tolist()))\n",
    "    features1 = feature_names[selected_features].tolist()\n",
    "        \n",
    "    model_selected = KNeighborsClassifier()\n",
    "    model_all = KNeighborsClassifier()\n",
    "    model_name = \"KNeighborsClassifier\"\n",
    "\n",
    "    model_selected.fit(X_train[:, selected_features], y_train)  \n",
    "    subset_acc = model_selected.score(X_test[:, selected_features], y_test)\n",
    "    print('Subset accuracy:', subset_acc)\n",
    "    if subset_acc > bestScore:\n",
    "        bestScore = subset_acc\n",
    "        bestCriterion = x\n",
    "        nep_num = selected_features.sum()\n",
    "        nep_features = feature_names[selected_features].tolist()\n",
    "    model_all.fit(X_train, y_train)\n",
    "    print('All Features Accuracy:', model_all.score(X_test, y_test))\n",
    "    \n",
    "    # SVC\n",
    "    task = Task(problem_svc, max_iters=200)\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    print(\"Bees algorithm: nep = \"+ str(x))\n",
    "    algorithm = BeesAlgorithm(population_size=40, m=5, e=4, ngh=1, nep=x, nsp=2)\n",
    "    best_features, best_fitness = algorithm.run(task=task)\n",
    "    selected_features = best_features > 0.5\n",
    "    print('Number of selected features:', selected_features.sum())\n",
    "    print('Selected features:', ', '.join(feature_names[selected_features].tolist()))\n",
    "    features1 = feature_names[selected_features].tolist()\n",
    "        \n",
    "    model_selected = SVC()\n",
    "    model_all = SVC()\n",
    "    model_name = \"SVC\"\n",
    "\n",
    "    model_selected.fit(X_train[:, selected_features], y_train)  \n",
    "    subset_acc = model_selected.score(X_test[:, selected_features], y_test)\n",
    "    print('Subset accuracy:', subset_acc)\n",
    "    if subset_acc > bestScore:\n",
    "        bestScore = subset_acc\n",
    "        bestCriterion = x\n",
    "        nep_num = selected_features.sum()\n",
    "        nep_features = feature_names[selected_features].tolist()\n",
    "    model_all.fit(X_train, y_train)\n",
    "    print('All Features Accuracy:', model_all.score(X_test, y_test))\n",
    "    \n",
    "beedict[\"Bees-NEP\"] = \"nep: \" + str(bestCriterion) + \", accuracy: \" + str(round(bestScore, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa515a04-658c-4b97-8c3e-79b60f7c2e6a",
   "metadata": {},
   "source": [
    "# Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a616ef9f-b55d-47a7-8265-240fd995f0f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df['target'] = dataset.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33ae4cdb-a49e-40bd-ac66-895885170744",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bees-Population': 'pop: 10, accuracy: 1.0',\n",
       " 'Bees-M': 'm: 4, accuracy: 0.99123',\n",
       " 'Bees-NEP': 'nep: 1, accuracy: 0.96491'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5827dabe-ba3d-45ce-bfcf-b2f951462d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop_num: 15, pop_features: ['mean radius', 'mean texture', 'mean smoothness', 'mean concavity', 'mean concave points', 'texture error', 'perimeter error', 'area error', 'compactness error', 'concavity error', 'concave points error', 'worst area', 'worst compactness', 'worst concave points', 'worst fractal dimension']\n",
      "m_num: 13, m_features: ['mean texture', 'mean concavity', 'mean concave points', 'mean fractal dimension', 'area error', 'compactness error', 'concavity error', 'symmetry error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points']\n",
      "nep_num: 11, nep_features: ['mean texture', 'mean area', 'mean concave points', 'mean symmetry', 'texture error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"pop_num: {}, pop_features: {}\\nm_num: {}, m_features: {}\\nnep_num: {}, nep_features: {}\\n\".format(pop_num, pop_features, m_num, m_features, nep_num, nep_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fd4b2f6-d330-4af7-9dd4-a0e6a3235ffa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean smoothness  mean concavity  \\\n",
       "0        17.99         10.38          0.11840          0.3001   \n",
       "1        20.57         17.77          0.08474          0.0869   \n",
       "2        19.69         21.25          0.10960          0.1974   \n",
       "3        11.42         20.38          0.14250          0.2414   \n",
       "4        20.29         14.34          0.10030          0.1980   \n",
       "\n",
       "   mean concave points  texture error  perimeter error  area error  \\\n",
       "0              0.14710         0.9053            8.589      153.40   \n",
       "1              0.07017         0.7339            3.398       74.08   \n",
       "2              0.12790         0.7869            4.585       94.03   \n",
       "3              0.10520         1.1560            3.445       27.23   \n",
       "4              0.10430         0.7813            5.438       94.44   \n",
       "\n",
       "   compactness error  concavity error  concave points error  worst area  \\\n",
       "0            0.04904          0.05373               0.01587      2019.0   \n",
       "1            0.01308          0.01860               0.01340      1956.0   \n",
       "2            0.04006          0.03832               0.02058      1709.0   \n",
       "3            0.07458          0.05661               0.01867       567.7   \n",
       "4            0.02461          0.05688               0.01885      1575.0   \n",
       "\n",
       "   worst compactness  worst concave points  worst fractal dimension  \n",
       "0             0.6656                0.2654                  0.11890  \n",
       "1             0.1866                0.1860                  0.08902  \n",
       "2             0.4245                0.2430                  0.08758  \n",
       "3             0.8663                0.2575                  0.17300  \n",
       "4             0.2050                0.1625                  0.07678  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf = df.drop(columns=[col for col in df if col not in pop_features])\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa42d3d3-e65a-4055-a508-318d081ccc7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 15) (569,)\n"
     ]
    }
   ],
   "source": [
    "y =  dataset.target\n",
    "X = newdf\n",
    "print(X.shape, y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 21)\n",
    "\n",
    "#Feature Scaling, this is important as itt will allow the algorithm to quickly learn a better solution.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a0bff4-77eb-4b1b-a904-49d087c20f02",
   "metadata": {},
   "source": [
    "# Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eda3548-d806-480f-97ee-25aa3bb5c632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gaussianNB():\n",
    "    \n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train,y_train)\n",
    "    y_pred_test = gnb.predict(X_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc = accuracy_score(y_test,y_pred_test)\n",
    "    print(\"Naive Bayes : \", acc)\n",
    "    b_class = [\"benign\", \"malign\"]\n",
    "    print(classification_report(y_test, y_pred_test, target_names=b_class))\n",
    "    \n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46cdad9-be70-47eb-88a4-089cbfe02979",
   "metadata": {},
   "source": [
    "# LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6625c1ae-8141-400c-8397-c51b67f0617e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def logisticRegression():\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    logreg = LogisticRegression(solver = 'liblinear',multi_class='auto')\n",
    "    logreg.fit(X_train,y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc1 = accuracy_score(y_test,y_pred)\n",
    "    print(\"Logistic Regression: \", acc1)\n",
    "    b_class = [\"benign\", \"malign\"]\n",
    "    print(classification_report(y_test, y_pred, target_names=b_class))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef44e162-a0c5-443e-b573-50d157a5614f",
   "metadata": {},
   "source": [
    "# Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e082e4db-677f-43ab-bba0-39aa07dd4c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decisionTrees():\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(X_train,y_train)\n",
    "    y_pred2 = dt.predict(X_test)\n",
    "    acc2 = accuracy_score(y_test,y_pred2)\n",
    "    print(acc2)\n",
    "    print(\"Decision Trees:\", acc2)\n",
    "    b_class = [\"benign\", \"malign\"]\n",
    "    print(classification_report(y_test, y_pred2, target_names=b_class))\n",
    "\n",
    "    return y_pred2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d74be9e-da5c-45df-a9cb-e518f573e167",
   "metadata": {},
   "source": [
    "# KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2aa6b68c-23a7-4df4-82a1-a44350ea468f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def knn():\n",
    "    \n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    clf = KNeighborsClassifier(n_neighbors=8,algorithm='ball_tree')\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred3 = clf.predict(X_test)\n",
    "    acc3 =   accuracy_score(y_test,y_pred3)\n",
    "    print(\"K Nearest Neighbors: \", acc3)\n",
    "    b_class = [\"benign\", \"malign\"]\n",
    "    print(classification_report(y_test, y_pred3, target_names=b_class))  \n",
    "    \n",
    "    return y_pred3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66032db8-98db-4908-97ef-4dca4d9a69aa",
   "metadata": {},
   "source": [
    "# Support Vector Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d53dc85-9f30-4e19-a2c4-3ad62f8a0a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def svc():\n",
    "    \n",
    "    from sklearn.svm import SVC\n",
    "    svc1 = SVC(C=50,kernel='rbf',gamma=1)     \n",
    "    svc1.fit(X_train,y_train)\n",
    "    y_pred4 = svc1.predict(X_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc4=    accuracy_score(y_test,y_pred4)\n",
    "    print(\"Support Vector Classifier Accuracy\", acc4)\n",
    "    b_class = [\"benign\", \"malign\"]\n",
    "    print(classification_report(y_test, y_pred4, target_names=b_class))  \n",
    "    \n",
    "    return y_pred4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ae643-3bf6-4505-bf87-11adad840717",
   "metadata": {},
   "source": [
    "# Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "504eeb09-f795-41f5-bd82-42b63361c35d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes :  0.9122807017543859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.87      0.87      0.87        39\n",
      "      malign       0.93      0.93      0.93        75\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.90      0.90      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "0.9210526315789473\n",
      "Decision Trees: 0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.89      0.87      0.88        39\n",
      "      malign       0.93      0.95      0.94        75\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.91      0.91      0.91       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "Logistic Regression:  0.9824561403508771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       1.00      0.95      0.97        39\n",
      "      malign       0.97      1.00      0.99        75\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.97      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Support Vector Classifier Accuracy 0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.83      0.97      0.89        39\n",
      "      malign       0.99      0.89      0.94        75\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.91      0.93      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "K Nearest Neighbors:  0.9912280701754386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       1.00      0.97      0.99        39\n",
      "      malign       0.99      1.00      0.99        75\n",
      "\n",
      "    accuracy                           0.99       114\n",
      "   macro avg       0.99      0.99      0.99       114\n",
      "weighted avg       0.99      0.99      0.99       114\n",
      "\n",
      "\n",
      "Now testing algorithms\n",
      "trained model:  gaussianNB\n",
      "trained model:  decisionTrees\n",
      "trained model:  logisticRegression\n",
      "trained model:  svc\n",
      "trained model:  knn\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "        \"gaussianNB\": gaussianNB(),\n",
    "        \"decisionTrees\": decisionTrees() ,\n",
    "        \"logisticRegression\": logisticRegression(),\n",
    "        \"svc\": svc(),\n",
    "        \"knn\": knn()\n",
    "    }\n",
    "\n",
    "results = {}\n",
    "print(\"\\nNow testing algorithms\")\n",
    "for algo in models:\n",
    "\n",
    "    print(\"trained model: \", algo )\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40e868b0-4471-4c3e-b1c7-725cb21a1fe3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bees-Population': 'pop: 10, accuracy: 1.0',\n",
       " 'Bees-M': 'm: 4, accuracy: 0.99123',\n",
       " 'Bees-NEP': 'nep: 1, accuracy: 0.96491'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e391340-7502-4c16-8f1c-56288529fa40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
