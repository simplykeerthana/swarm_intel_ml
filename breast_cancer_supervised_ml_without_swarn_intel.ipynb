{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5caffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 algorithm implementation \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.ensemble as ske\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.ensemble as ske\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47c3a53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_breast_cancer()\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df['target'] = dataset.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32541ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31) (569,)\n"
     ]
    }
   ],
   "source": [
    "y =  dataset.target\n",
    "X = df\n",
    "print(X.shape, y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 21)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aa1b730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 0\n",
      " 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0\n",
      " 1 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       1.00      1.00      1.00        39\n",
      "     maliant       1.00      1.00      1.00        75\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "clf= svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred =clf.predict(X_test)\n",
    "print(y_pred)\n",
    "b_class = [\"benign\", \"maliant\"]\n",
    "print(classification_report(y_test, y_pred, target_names=b_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b054ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 0\n",
      " 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0\n",
      " 1 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       1.00      1.00      1.00        39\n",
      "      malign       1.00      1.00      1.00        75\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "\n",
    "clf_nb = GaussianNB()\n",
    "clf_nb.fit(X_train, y_train)\n",
    "y_pred1 = clf.predict(X_test)\n",
    "print(y_pred1)\n",
    "b_class = [\"benign\", \"malign\"]\n",
    "print(classification_report(y_test, y_pred1, target_names=b_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d759dfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling, this is important as itt will allow the algorithm to quickly learn a better solution.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b69c2af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianNB():\n",
    "    \n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train,y_train)\n",
    "    y_pred_test = gnb.predict(X_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc = accuracy_score(y_test,y_pred_test)\n",
    "    print(\"Naive Bayes : \", acc)\n",
    "    b_class = [\"benign\", \"malign\"]\n",
    "    print(classification_report(y_test, y_pred_test, target_names=b_class))\n",
    "    \n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "853cafff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression():\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    logreg = LogisticRegression(solver = 'liblinear',multi_class='auto')\n",
    "    logreg.fit(X_train,y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc1 = accuracy_score(y_test,y_pred)\n",
    "    print(\"Logistic Regression: \", acc1)\n",
    "    b_class = [\"benign\", \"malign\"]\n",
    "    print(classification_report(y_test, y_pred, target_names=b_class))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12285180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTrees():\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    dt = DecisionTreeClassifier()\n",
    "    dt.fit(X_train,y_train)\n",
    "    y_pred2 = dt.predict(X_test)\n",
    "    acc2 = accuracy_score(y_test,y_pred2)\n",
    "    print(acc2)\n",
    "    print(\"Decision Trees:\", acc2)\n",
    "    b_class = [\"benign\", \"malign\"]\n",
    "    print(classification_report(y_test, y_pred2, target_names=b_class))\n",
    "\n",
    "    return y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8ec05a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn():\n",
    "    \n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    clf = KNeighborsClassifier(n_neighbors=8,algorithm='ball_tree')\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred3 = clf.predict(X_test)\n",
    "    acc3 =   accuracy_score(y_test,y_pred3)\n",
    "    print(\"K Nearest Neighbors: \", acc3)\n",
    "    b_class = [\"benign\", \"malign\"]\n",
    "    print(classification_report(y_test, y_pred3, target_names=b_class))  \n",
    "    \n",
    "    return y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efd20ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc(flag):\n",
    "    \n",
    "    from sklearn.svm import SVC\n",
    "    svc1 = SVC(C=50,kernel='rbf',gamma=1)     \n",
    "    svc1.fit(X_train,y_train)\n",
    "    y_pred4 = svc1.predict(X_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    acc4=    accuracy_score(y_test,y_pred4)\n",
    "    print(\"Support Vector Classifier Accuracy\", acc4)\n",
    "    b_class = [\"benign\", \"malign\"]\n",
    "    print(classification_report(y_test, y_pred4, target_names=b_class))  \n",
    "    \n",
    "    return y_pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dcc301a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes :  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       1.00      1.00      1.00        39\n",
      "      malign       1.00      1.00      1.00        75\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n",
      "1.0\n",
      "Decision Trees: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       1.00      1.00      1.00        39\n",
      "      malign       1.00      1.00      1.00        75\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n",
      "Logistic Regression:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       1.00      1.00      1.00        39\n",
      "      malign       1.00      1.00      1.00        75\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n",
      "Support Vector Classifier Accuracy 0.6754385964912281\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       1.00      0.05      0.10        39\n",
      "      malign       0.67      1.00      0.80        75\n",
      "\n",
      "    accuracy                           0.68       114\n",
      "   macro avg       0.83      0.53      0.45       114\n",
      "weighted avg       0.78      0.68      0.56       114\n",
      "\n",
      "K Nearest Neighbors:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       1.00      1.00      1.00        39\n",
      "      malign       1.00      1.00      1.00        75\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n",
      "\n",
      "Now testing algorithms\n",
      "trained model:  gaussianNB\n",
      "trained model:  decisionTrees\n",
      "trained model:  logisticRegression\n",
      "trained model:  svc\n",
      "trained model:  knn\n",
      "\n",
      "\n",
      "gaussianNB [1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 0\n",
      " 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0\n",
      " 1 1 0]\n",
      "decisionTrees [1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 0\n",
      " 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0\n",
      " 1 1 0]\n",
      "logisticRegression [1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 0\n",
      " 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0\n",
      " 1 1 0]\n",
      "svc [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1]\n",
      "knn [1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 0\n",
      " 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0\n",
      " 1 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keert\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "        \"gaussianNB\": gaussianNB(),\n",
    "        \"decisionTrees\": decisionTrees() ,\n",
    "        \"logisticRegression\": logisticRegression(),\n",
    "        \"svc\": svc(1),\n",
    "        \"knn\": knn()\n",
    "    }\n",
    "\n",
    "results = {}\n",
    "print(\"\\nNow testing algorithms\")\n",
    "for algo in models:\n",
    "\n",
    "    print(\"trained model: \", algo )\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for key, value in models.items():\n",
    "    results[key] = value\n",
    "    print(key, value)\n",
    "    \n",
    "\n",
    "# winner = max(results, key=results.get)\n",
    "# print(\"the winner algorithm is \", winner)\n",
    "# print('\\nWinner algorithm is %s with a %f %% success' % (winner, results[winner]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab1a729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc72e9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42831de8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
